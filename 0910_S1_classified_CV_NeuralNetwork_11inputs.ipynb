{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reference from: </h1>\n",
    "<ul>\n",
    "<li><a href=\"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class04_training.ipynb\">Part 4.3: Cross-Validation for Neural Networks from <i>jeffheaton</i></a>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3436, 6)\n",
      "Fold #1\n",
      "Epoch 00094: early stopping\n",
      "Fold score (bingo-accuracy): 0.39680232558139533\n",
      "Fold score (1 away-accuracy): 0.8183139534883721\n",
      "Fold #2\n",
      "Epoch 00107: early stopping\n",
      "Fold score (bingo-accuracy): 0.5109170305676856\n",
      "Fold score (1 away-accuracy): 0.9068413391557496\n",
      "Fold #3\n",
      "Epoch 00142: early stopping\n",
      "Fold score (bingo-accuracy): 0.4512372634643377\n",
      "Fold score (1 away-accuracy): 0.87627365356623\n",
      "Fold #4\n",
      "Epoch 00086: early stopping\n",
      "Fold score (bingo-accuracy): 0.4963609898107715\n",
      "Fold score (1 away-accuracy): 0.8748180494905385\n",
      "Fold #5\n",
      "Epoch 00047: early stopping\n",
      "Fold score (bingo-accuracy): 0.42212518195050946\n",
      "Fold score (1 away-accuracy): 0.8049490538573508\n",
      "\n",
      "Final score (accuracy): 0.45547147846332947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "'''\n",
    "path = \"./data/\"\n",
    "\n",
    "#filename_read = os.path.join(path,\"iris.csv\")\n",
    "#filename_write = os.path.join(path,\"iris-out-of-sample.csv\")\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Encode to a 2D matrix for training\n",
    "species = encode_text_index(df,\"species\")\n",
    "x,y = to_xy(df,\"species\")\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "cols=['genre__Action',\n",
    "      'genre__Adventure', \n",
    "      'genre__Animation', \n",
    "      'genre__Biography', \n",
    "      'genre__Comedy', \n",
    "      'genre__Crime', \n",
    "      'genre__Documentary', \n",
    "      'genre__Drama', \n",
    "      'genre__Family', \n",
    "      'genre__Horror', \n",
    "      'genre__Music', \n",
    "      'genre__Mystery',\n",
    "      'genre__Sci-Fi',\n",
    "      'star', \n",
    "      'runtime',\n",
    "      'user',\n",
    "      'critc',\n",
    "      'dir_popu',\n",
    "      'ac1_popu',\n",
    "      'ac2_popu',\n",
    "      'ac3_popu',\n",
    "      #'n_of_posters', \n",
    "      #'opening_box_office',\n",
    "      'budget_mixed',\n",
    "      #'year_encode'\n",
    "     ] \n",
    "\n",
    "target = \"target_paper_label\"\n",
    "###################################################    \n",
    "\n",
    "all_df = pd.read_excel('6cate/O_H_all_6cate_3436_movie_0830.xlsx')\n",
    "y_df = pd.read_excel('6cate/O_H_all_6cate_3436_movie_0830.xlsx')\n",
    "all_df = all_df[cols]\n",
    "#print(train_df)\n",
    "y_all=y_df[target]\n",
    "\n",
    "y_all = np_utils.to_categorical(y_all, num_classes=6)\n",
    "print(y_all.shape)\n",
    "\n",
    "all_df = all_df.values\n",
    "\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))  \n",
    "all_df = minmax_scale.fit_transform(all_df)\n",
    "\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(all_df):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = all_df[train]\n",
    "    y_train = y_all[train]\n",
    "    x_test = all_df[test]\n",
    "    y_test = y_all[test]\n",
    "    \n",
    "    model = Sequential()  \n",
    "            \n",
    "    model.add(Dense(units=72, input_dim=len(cols), kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=108, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=128, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=192, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=256, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=192, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=128, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=108, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=72, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units=6,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"Fold score (bingo-accuracy): {}\".format(score))\n",
    "\n",
    "    CM = confusion_matrix(y_compare, pred)    \n",
    "    bingo = 0\n",
    "    one_away = 0\n",
    "    for i in range(0, 6):\n",
    "        #print(CM[i][i]) ## bingo\n",
    "        bingo = bingo + CM[i][i]\n",
    "       # print('BINGO: ', bingo)\n",
    "    one_away = CM[0][1] + CM[1][2] + CM[2][3] +  CM[3][4] +  CM[4][5] +  CM[1][0] +  CM[2][1] +  CM[3][2] +  CM[4][3] +  CM[5][4] \n",
    "    #print('1-AWAY: ',one_away)\n",
    "    #print('total: ',bingo+one_away)\n",
    "    score_1away = (bingo+one_away)/len(y_compare)\n",
    "    print(\"Fold score (1 away-accuracy): {}\".format(score_1away))\n",
    "\n",
    "print()\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(\"Final score (accuracy): {}\".format(score))    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "#oos_y = pd.DataFrame(oos_y)\n",
    "#oos_pred = pd.DataFrame(oos_pred)\n",
    "#oosDF = pd.concat( [all_df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv('dadada.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20,  48,   7,  10,  10,  10],\n",
       "       [ 13,  68,  17,   5,   7,   4],\n",
       "       [  7,  39,  30,  20,   6,   2],\n",
       "       [  0,  22,  28,  25,  25,   4],\n",
       "       [  0,   7,  17,  19,  36,  16],\n",
       "       [  0,   2,   7,   7,  38, 111]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_compare\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(y_compare, pred)\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINGO:  290\n",
      "1-AWAY:  263\n",
      "total:  553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80494905385735083"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bingo = 0\n",
    "one_away = 0\n",
    "\n",
    "for i in range(0, 6):\n",
    "    #print(CM[i][i]) ## bingo\n",
    "    bingo = bingo + CM[i][i]\n",
    "print('BINGO: ', bingo)\n",
    "\n",
    "one_away = CM[0][1] + CM[1][2] + CM[2][3] +  CM[3][4] +  CM[4][5] +  CM[1][0] +  CM[2][1] +  CM[3][2] +  CM[4][3] +  CM[5][4] \n",
    "print('1-AWAY: ',one_away)\n",
    "print('total: ',bingo+one_away)\n",
    "\n",
    "(bingo+one_away)/len(y_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
